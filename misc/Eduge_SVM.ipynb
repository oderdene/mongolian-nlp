{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eduge_SVM_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "y-T1zgYq_sEQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mongolian News Classification\n",
        "\n",
        "This notebook contains a simple demo classifying the [Eduge news dataset](https://github.com/tugstugi/mongolian-nlp) provided by [Bolorsoft LLC](https://bolorsoft.com/) using a SVM and [SentencePiece](https://github.com/google/sentencepiece).\n",
        "\n",
        "## Download Eduge dataset"
      ]
    },
    {
      "metadata": {
        "id": "oRzVjcQ7xdGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "if not exists(\"eduge.csv\"):\n",
        "  !wget -q https://github.com/tugstugi/mongolian-nlp/raw/master/datasets/eduge.csv.gz\n",
        "  !gunzip eduge.csv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hc7Q18GdAoKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download SentencePiece vocabulary\n",
        "\n",
        "A SentencePiece model trained on a Mongolian corpus containg 650M words will be used the text tokenizer. We will download it from the repo [tugstugi/mongolian-bert](https://github.com/tugstugi/mongolian-bert):\n"
      ]
    },
    {
      "metadata": {
        "id": "fTY_S9iHxl_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not exists('mn_uncased.model'):\n",
        "  # download both SentencePiece models: cased and uncased\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_cased.model\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_cased.vocab\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_uncased.model\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_uncased.vocab\n",
        "    \n",
        "  # install SentencePiece\n",
        "  !pip install -q sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9Ao4LXDCH1L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load SentencePiece and test\n",
        "\n",
        "Load the downloaded SentencePiece model and tokenize some text:"
      ]
    },
    {
      "metadata": {
        "id": "wIPCSjHFyQvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e8b7253-8cf3-4abd-928f-225febbbcfc6"
      },
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load('mn_uncased.model')\n",
        "def sp_tokenize(w):\n",
        "  return sp.EncodeAsPieces(w)\n",
        "\n",
        "\" \".join(sp_tokenize('Мөнгөө тушаачихсаныхаа дараа мэдэгдээрэй'.lower()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁мөнгөө ▁тушаа чихсан ыхаа ▁дараа ▁мэдэгд ээрэй'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "ZPS3zFeyCiNy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train/Test split"
      ]
    },
    {
      "metadata": {
        "id": "TRvYlCAoytvf",
        "colab_type": "code",
        "outputId": "b8323036-e60e-4d70-b7b1-9a7b07b36aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"eduge.csv\")\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "\n",
        "# show labels\n",
        "print('labels', df['label'].unique().tolist())\n",
        "\n",
        "# stratified train and test split\n",
        "train, test = train_test_split(df, test_size=0.1, random_state=999, stratify=df['label'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels ['урлаг соёл', 'эдийн засаг', 'эрүүл мэнд', 'хууль', 'улс төр', 'спорт', 'технологи', 'боловсрол', 'байгал орчин']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qClJ6pA-C84c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train SVM\n",
        "\n",
        "Now train a SVM, no hyperparameter optimization, use only some default parameters:"
      ]
    },
    {
      "metadata": {
        "id": "Bhve5JIHzF9l",
        "colab_type": "code",
        "outputId": "d3eb8a06-644f-4570-ab3d-d97ec86b1588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer(tokenizer=sp_tokenize, lowercase=True)),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-4, n_iter=5, random_state=0))])\n",
        "\n",
        "t = time.time()\n",
        "text_clf = text_clf.fit(train['news'], train['label'])\n",
        "t = time.time()-t\n",
        "print(\"Training time in seconds: \", t)\n",
        "\n",
        "t = time.time()\n",
        "predicted = text_clf.predict(test['news'])\n",
        "t = time.time()-t\n",
        "print(\"Prediction time in seconds: \", t)\n",
        "\n",
        "print(\"Feature count:\", len(text_clf.named_steps['vect'].vocabulary_))\n",
        "print(\"Classifier accuracy: \", np.mean(predicted == test['label']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training time in seconds:  158.1350929737091\n",
            "Prediction time in seconds:  17.703580856323242\n",
            "Feature count: 32231\n",
            "Classifier accuracy:  0.9093432007400555\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}